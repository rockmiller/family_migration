{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcfcsv = 'codebook_batches_15.csv'\n",
    "bcf = pd.read_csv(r'D:\\\\Documents\\\\conversion\\\\1_data import\\\\'+bcfcsv)\n",
    "batchproc = bcf['batch'].tolist()\n",
    "dctp = bcf.loc[bcf['batch'].isin(batchproc)].to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_codebook(cbkpickle):\n",
    "    cbdf = pd.read_pickle(cbkpickle)\n",
    "    return cbdf\n",
    "\n",
    "def create_column_list(cbdf):\n",
    "    x = cbdf['length'].astype('str')\n",
    "    cbdf['column_name'] = cbdf['variable'].str.lower() + ' char('+x+')'\n",
    "    column_list = cbdf['column_name'].tolist()\n",
    "    print (len(column_list),'columns')\n",
    "    return column_list\n",
    "\n",
    "def create_slice_list(cbdf):\n",
    "    slice_list = cbdf['slice_obj'].tolist()\n",
    "    return slice_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_record(line, slices):\n",
    "    limit = len(line)\n",
    "    rlist = []\n",
    "    for i in slices:\n",
    "        len_slice = len(line[i])\n",
    "        begin = limit\n",
    "        limit = limit - len_slice\n",
    "        if limit <= 0: break\n",
    "        rlist.append(line[i])\n",
    "    textrec = '|'.join(rlist)+'\\n'\n",
    "    return textrec\n",
    "\n",
    "def read_datafile(datafile, slice_list):\n",
    "    with open(datafile,'r') as f:\n",
    "        records = []\n",
    "        print('Processing Records from '+datafile)\n",
    "        while (True):\n",
    "            line = f.readline()\n",
    "            if line == \"\": break\n",
    "            records.append((slice_record(line, slice_list)))\n",
    "    print ('Done')\n",
    "    print(len(records),'records')\n",
    "    return records\n",
    "\n",
    "def write_datafile(records, outfile):\n",
    "    with open (outfile,'w') as wf:\n",
    "        for i in records:\n",
    "            wf.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dctp:\n",
    "    print (i['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data into Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dctp:\n",
    "    cbkfile = i['path']+'\\\\'+i['cbkname']+'.pickle'\n",
    "    datafile = i['path']+'\\\\'+i['datafile']\n",
    "    outfile = i['path']+'\\\\'+i['cendata']+'.text'\n",
    "    cbdf = read_codebook(cbkfile)\n",
    "    slice_list = create_slice_list(cbdf)\n",
    "    data = read_datafile(datafile,slice_list)\n",
    "    write_datafile(data,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_database(database):\n",
    "    conn = psycopg2.connect(dbname=database, user='postgres', password = '3701', host='localhost', port='5432')\n",
    "    return conn\n",
    "\n",
    "def create_cursor():\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "\n",
    "def set_census_schema():\n",
    "    cursor.execute(\"SET SCHEMA 'production'\")\n",
    "\n",
    "def close_database():\n",
    "    #insert rollback logic\n",
    "    print('committing the records')\n",
    "    conn.commit()\n",
    "    conn.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(tablename, columns):\n",
    "    columns_text = '(' + ', '.join(columns) + ');'\n",
    "    cursor.execute('DROP TABLE IF EXISTS ' + tablename + ';')\n",
    "    cursor.execute('CREATE TABLE ' + tablename + ' ' + columns_text+';')\n",
    "    conn.commit()\n",
    "\n",
    "def insert_values(tablename, column_list):\n",
    "    #slice is one record\n",
    "    columns_text = '(' + ', '.join(column_list) + ');'\n",
    "    cursor.execute('INSERT CREATE TABLE ' + tablename + ' ' + columns_text+';')\n",
    "\n",
    "def clear_table(tablename):\n",
    "    clear = 'DELETE FROM ' + tablename\n",
    "\n",
    "def insert_data(datafile, slice_list):\n",
    "    with open(datafile,'r') as f:\n",
    "        records = []\n",
    "        print('Processing Records '+'Batch '+str(batch))\n",
    "        while (True):\n",
    "            line = f.readline()\n",
    "            if line == \"\": break\n",
    "            records.append((slice_record(line, slice_list)))\n",
    "    print ('Done')\n",
    "    print(len(records),'records')\n",
    "    return records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
