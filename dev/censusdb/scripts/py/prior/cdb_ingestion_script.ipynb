{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4788928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import typing\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime, timezone\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cba5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Folders\n",
    "BASEPATH = Path(\"D:/censusdb\")\n",
    "SOURCEPATH = Path(\"D:/source\")\n",
    "BUCKETS_CSV = Path(\"D:/censusdb/parameters\") / 'nbuckets.csv'\n",
    "\n",
    "folder_map = {\n",
    "    \"1850\": BASEPATH / \"cp1850\",\n",
    "    \"1860\": BASEPATH / \"cp1860\",\n",
    "    \"1870\": BASEPATH / \"cp1870\",\n",
    "    \"1880\": BASEPATH / \"cp1880\",\n",
    "    \"1890\": BASEPATH / \"cp1890\",\n",
    "    \"1900\": BASEPATH / \"cp1900\",\n",
    "    \"1910\": BASEPATH / \"cp1910\",\n",
    "    \"1920\": BASEPATH / \"cp1920\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba904263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bucket counts from CSV\n",
    "def load_bucket_map(bucket_csv: Path) -> dict[int, int]:\n",
    "    df = pl.read_csv(bucket_csv)\n",
    "    return {row[\"cenyear\"]: row[\"N_BUCKETS\"] for row in df.to_dicts()}\n",
    "\n",
    "bucket_map = load_bucket_map(BUCKETS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc87b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_for_year(cenyear: int, out_root: Path) -> dict:\n",
    "    csv_root = SOURCEPATH\n",
    "    csv_template = \"cs{cenyear}.csv.gz\"\n",
    "    index_db = BASEPATH / \"index\" / \"search_index.duckdb\"\n",
    "    manifest_db = BASEPATH / \"manifests\" / \"manifest.duckdb\"\n",
    "\n",
    "    if cenyear not in bucket_map:\n",
    "        raise ValueError(f\"No bucket count defined for year {cenyear}\")\n",
    "\n",
    "    csv_path = csv_root / csv_template.format(cenyear=cenyear)\n",
    "    bucket_count = bucket_map[cenyear]\n",
    "\n",
    "    return {\n",
    "        \"cenyear\": cenyear,\n",
    "        \"csv\": csv_path,\n",
    "        \"bucket_count\": bucket_count,\n",
    "        \"out_root\": out_root,\n",
    "        \"index_db\": index_db,\n",
    "        \"manifest_db\": manifest_db,\n",
    "        \"state_col\": \"stateicp\",\n",
    "        \"county_col\": \"countyicp\",\n",
    "        \"serial_col\": \"serial\",\n",
    "        \"histid_col\": \"histid\",\n",
    "        \"hik_col\": \"hik\",\n",
    "        \"read_csv_opts\": {\n",
    "            \"has_header\": True,\n",
    "            \"separator\": \",\",\n",
    "            \"infer_schema_length\": 10000\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c544d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_for_filename(filename: str, folder_map: dict[str, Path]) -> dict:\n",
    "    stem = Path(filename).stem\n",
    "    cenyear_str = stem[2:6]\n",
    "    cenyear = int(cenyear_str)\n",
    "\n",
    "    if cenyear_str not in folder_map:\n",
    "        raise ValueError(f\"No output folder defined for cenyear {cenyear_str}\")\n",
    "\n",
    "    out_root = folder_map[cenyear_str]\n",
    "    return config_for_year(cenyear, out_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75024d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output_dirs(config: dict):\n",
    "    os.makedirs(config[\"out_root\"], exist_ok=True)\n",
    "    os.makedirs(config[\"index_db\"].parent, exist_ok=True)\n",
    "    os.makedirs(config[\"manifest_db\"].parent, exist_ok=True)\n",
    "\n",
    "def read_input_csv(config: dict) -> pl.DataFrame:\n",
    "    return pl.read_csv(source=config[\"csv\"], **config[\"read_csv_opts\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b005cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_composite_keys(df: pl.DataFrame, config: dict) -> pl.DataFrame:\n",
    "    df = df.with_columns([\n",
    "        pl.lit(config[\"cenyear\"]).cast(str).str.zfill(4).alias(\"cenyear_str\"),\n",
    "        pl.col(config[\"serial_col\"]).cast(str).str.zfill(6).alias(\"serial_str\"),\n",
    "        pl.col(config[\"state_col\"]).cast(str).str.zfill(2).alias(\"state_str\"),\n",
    "        pl.col(config[\"county_col\"]).cast(str).str.zfill(4).alias(\"county_str\"),\n",
    "        pl.col(config[\"histid_col\"]).cast(str).str.zfill(36).alias(\"histid_str\")\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"cenyear_str\") + pl.col(\"serial_str\")).alias(\"hhid\"),\n",
    "        (pl.col(\"state_str\") + pl.col(\"county_str\")).alias(\"cloc\"),\n",
    "        (pl.col(\"cenyear_str\") + pl.col(\"serial_str\") + pl.col(\"histid_str\")).alias(\"cper\")\n",
    "    ])\n",
    "\n",
    "    df = df.sort([\"cenyear\", \"hhid\"])\n",
    "    df = df.with_row_index(name=\"rownum\")\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"rownum\") % config[\"bucket_count\"]).alias(\"bucket\")\n",
    "    ])\n",
    "\n",
    "    return df.drop([\"cenyear_str\", \"serial_str\", \"state_str\", \"county_str\", \"histid_str\", \"rownum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4356b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_buckets_and_collect_manifest(df: pl.DataFrame, config: dict) -> list[dict]:\n",
    "    manifest_rows = []\n",
    "\n",
    "    for b in range(config[\"bucket_count\"]):\n",
    "        bucket_df = df.filter(pl.col(\"bucket\") == b).drop(\"bucket\")\n",
    "        if bucket_df.is_empty():\n",
    "            continue\n",
    "\n",
    "        bucket_path = config[\"out_root\"] / f\"bucket_{b:02}.parquet\"\n",
    "        bucket_df.write_parquet(bucket_path, compression=\"zstd\")\n",
    "\n",
    "        manifest_rows.append({\n",
    "            \"cenyear\": config[\"cenyear\"],\n",
    "            \"bucket\": b,\n",
    "            \"file\": str(bucket_path),\n",
    "            \"record_count\": bucket_df.shape[0],\n",
    "            \"min_hhid\": bucket_df[\"hhid\"].min(),\n",
    "            \"max_hhid\": bucket_df[\"hhid\"].max(),\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "        })\n",
    "\n",
    "    return manifest_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80dd88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_manifest(manifest_rows: list[dict], config: dict):\n",
    "    \"\"\"\n",
    "    Writes manifest metadata to DuckDB with enforced schema and timestamp.\n",
    "    \"\"\"\n",
    "    # Ensure all expected columns exist\n",
    "    expected_columns = [\n",
    "        \"cenyear\", \"bucket\", \"file\", \"record_count\",\n",
    "        \"min_hhid\", \"max_hhid\", \"timestamp\"\n",
    "    ]\n",
    "\n",
    "    # Fill missing fields and enforce timestamp\n",
    "    for row in manifest_rows:\n",
    "        for col in expected_columns:\n",
    "            row.setdefault(col, None)\n",
    "        if not row[\"timestamp\"]:\n",
    "            row[\"timestamp\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Create Polars DataFrame with explicit types\n",
    "    df = pl.DataFrame(manifest_rows).select([\n",
    "        pl.col(\"cenyear\").cast(pl.Int32),\n",
    "        pl.col(\"bucket\").cast(pl.Int32),\n",
    "        pl.col(\"file\").cast(pl.Utf8),\n",
    "        pl.col(\"record_count\").cast(pl.Int32),\n",
    "        pl.col(\"min_hhid\").cast(pl.Utf8),\n",
    "        pl.col(\"max_hhid\").cast(pl.Utf8),\n",
    "        pl.col(\"timestamp\").cast(pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    # Optional: print schema for debugging\n",
    "    print(\"Manifest DataFrame schema:\", df.schema)\n",
    "\n",
    "    with duckdb.connect(str(config[\"manifest_db\"])) as con:\n",
    "        con.execute(\"DROP TABLE IF EXISTS manifest;\")\n",
    "        con.execute(\"\"\"\n",
    "        CREATE TABLE manifest (\n",
    "            cenyear INTEGER,\n",
    "            bucket INTEGER,\n",
    "            file TEXT,\n",
    "            record_count INTEGER,\n",
    "            min_hhid TEXT,\n",
    "            max_hhid TEXT,\n",
    "            timestamp TEXT,\n",
    "            PRIMARY KEY (cenyear, bucket)\n",
    "        );\n",
    "    \"\"\")\n",
    "        con.register(\"manifest_rows\", df)\n",
    "\n",
    "        # Optional: inspect registered table schema\n",
    "        print(con.execute(\"DESCRIBE manifest\").fetchall())\n",
    "        con.execute(\"DELETE FROM manifest WHERE cenyear = ?;\", [config[\"cenyear\"]])\n",
    "        con.execute(\"\"\"\n",
    "        INSERT INTO manifest (\n",
    "        cenyear, bucket, file, record_count,\n",
    "        min_hhid, max_hhid, timestamp\n",
    "        )\n",
    "        SELECT\n",
    "            mr.cenyear, mr.bucket, mr.file, mr.record_count,\n",
    "            mr.min_hhid, mr.max_hhid, mr.timestamp\n",
    "        FROM manifest_rows AS mr;\n",
    "    \"\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ebadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4238bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_index(df: pl.DataFrame, config: dict, cenyear: int):\n",
    "    index_df = df.filter(pl.col(config[\"hik_col\"]).is_not_null()).select([\n",
    "        config[\"hik_col\"], \"hhid\", \"cloc\"\n",
    "    ]).rename({config[\"hik_col\"]: \"hik\", \"cloc\": \"locid\"})\n",
    "\n",
    "    with duckdb.connect(str(config[\"index_db\"])) as con:\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS index (\n",
    "                hik     TEXT PRIMARY KEY,\n",
    "                hhid    TEXT,\n",
    "                locid   TEXT,\n",
    "                cenyear INTEGER\n",
    "            );\n",
    "        \"\"\")\n",
    "        con.register(\"index_df\", index_df)\n",
    "        con.execute(\"DELETE FROM index WHERE hik IN (SELECT hik FROM index_df);\")\n",
    "        con.execute(\"INSERT INTO index SELECT * FROM index_df;\")\n",
    "        print(f\"Cenyear {cenyear}: Appended {index_df.shape[0]} rows to search index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018a6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_record_counts(config: dict, filename: str) -> dict:\n",
    "    # 1. Source CSV\n",
    "    csv_path = Path(config[\"source_dir\"]) / filename\n",
    "    df_source = pl.read_csv(csv_path, infer_schema_length=1000)\n",
    "    source_count = df_source.shape[0]\n",
    "\n",
    "    # 2. Census DataFrame (after enrichment)\n",
    "    df_census = ingest_file(filename, config[\"folder_map\"])\n",
    "    df_census = add_composite_keys(df_census, config)\n",
    "    census_count = df_census.shape[0]\n",
    "\n",
    "    # 3. Manifest table in DuckDB\n",
    "    with duckdb.connect(str(config[\"manifest_db\"])) as con:\n",
    "        manifest_count = con.execute(\n",
    "            \"SELECT COUNT(*) FROM manifest WHERE cenyear = ?;\",\n",
    "            [config[\"cenyear\"]]\n",
    "        ).fetchone()[0]\n",
    "\n",
    "    # 4. Search index table in DuckDB\n",
    "    with duckdb.connect(str(config[\"index_db\"])) as con:\n",
    "        index_count = con.execute(\n",
    "            \"SELECT COUNT(*) FROM index WHERE cenyear = ?;\",\n",
    "            [config[\"cenyear\"]]\n",
    "        ).fetchone()[0]\n",
    "\n",
    "    return {\n",
    "        \"source_csv\": source_count,\n",
    "        \"census_frame\": census_count,\n",
    "        \"manifest_table\": manifest_count,\n",
    "        \"search_index\": index_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4583fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_one_file(filename: str, folder_map: dict[str, Path]):\n",
    "    config = config_for_filename(filename, folder_map)\n",
    "    prepare_output_dirs(config)\n",
    "    start = time.perf_counter()\n",
    "    df_source = read_input_csv(config)\n",
    "    df_census = add_composite_keys(df_source, config)\n",
    "    df_manifest = pl.DataFrame(manifest_rows)\n",
    "    manifest_rows = write_buckets_and_collect_manifest(df, config)\n",
    "    write_manifest(manifest_rows, config)\n",
    "    with duckdb.connect(str(config[\"manifest_db\"])) as con:\n",
    "        result = con.execute(\"SELECT * FROM manifest WHERE cenyear = ? ORDER BY bucket;\", [config[\"cenyear\"]]).fetchdf()\n",
    "    build_search_index(df_census, config, config[\"cenyear\"])\n",
    "    end = time.perf_counter()\n",
    "    print(f\"âœ… Finished processing {filename} in {round(end - start, 2)} seconds.\")\n",
    "    report_record_counts(config, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f08ceaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m filelist = [\u001b[33m\"\u001b[39m\u001b[33mcs1850.csv.gz\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filelist:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mingest_one_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mingest_one_file\u001b[39m\u001b[34m(filename, folder_map)\u001b[39m\n\u001b[32m      7\u001b[39m manifest_rows = write_buckets_and_collect_manifest(df_census, config)\n\u001b[32m      8\u001b[39m df_manifest = pl.DataFrame(manifest_rows)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m manifest_rows = write_buckets_and_collect_manifest(\u001b[43mdf\u001b[49m, config)\n\u001b[32m     10\u001b[39m write_manifest(manifest_rows, config)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m duckdb.connect(\u001b[38;5;28mstr\u001b[39m(config[\u001b[33m\"\u001b[39m\u001b[33mmanifest_db\u001b[39m\u001b[33m\"\u001b[39m])) \u001b[38;5;28;01mas\u001b[39;00m con:\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Execution\n",
    "filelist = [\"cs1850.csv.gz\"]\n",
    "for filename in filelist:\n",
    "    ingest_one_file(filename, folder_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (family_migration)",
   "language": "python",
   "name": "family_migration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
