{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Codebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Libraries and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'batch': 15, 'desc': 'w tennessee', 'path': 'D:\\\\Documents\\\\datafiles\\\\batch15 - w tenn', 'cbkfilename': 'usa_00026.cbk', 'cbkname': 'cbk15', 'datafile': 'usa_00026.dat', 'cendata': 'cen15', 'cbkcol': 'variable,basis,range,length', 'pattern': '\\\\s{2}(\\\\w+)\\\\s+([HP])\\\\s+([0-9,-]+)\\\\s+(\\\\d+)'}]\n"
     ]
    }
   ],
   "source": [
    "bcfcsv = 'codebook_batches_15.csv'\n",
    "bcf = pd.read_csv(r'D:\\\\Documents\\\\conversion\\\\1_data import\\\\'+bcfcsv)\n",
    "varlist = bcf.columns.tolist()\n",
    "batchproc = bcf['batch'].tolist()\n",
    "#batchproc = [1]\n",
    "dctp = bcf.loc[bcf['batch'].isin(batchproc)].to_dict(orient='records')\n",
    "print(dctp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codebook Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_codebook_text(cbkfile, pattern):\n",
    "    with open(cbkfile, 'r') as f:\n",
    "        text = f.read()       \n",
    "        cbkdat = re.findall(pattern, text)\n",
    "    return cbkdat\n",
    "\n",
    "def codebook_to_df(cbkdat, cbkcols):\n",
    "    cbk = pd.DataFrame.from_records(cbkdat,columns=cbkcols)\n",
    "    return cbk\n",
    "\n",
    "def parse_codebook(cbdf):\n",
    "    a = cbdf['range'].str.replace('-',',').str.split(',').tolist()\n",
    "    b = [[int(i) for i in j] for j in a]\n",
    "    c = []\n",
    "    for i in b:\n",
    "        i[0] = i[0]-1\n",
    "        c.append(i)\n",
    "    #print(c)\n",
    "    return c\n",
    "\n",
    "def slice_codebook(c):\n",
    "    sl=[]\n",
    "    for i in c:\n",
    "        if len(i) == 1: i.append(i[0]+1)\n",
    "        s = slice(i[0],i[1])  \n",
    "        sl.append(s)\n",
    "    print('Batch:',batch,'Length of data:',len(cbdf), len(c),len(sl))\n",
    "    return sl\n",
    "\n",
    "def save_codebook(cbdf, c, sl, cbkpickle):   \n",
    "    dfx = pd.DataFrame(c)\n",
    "    dfx.columns = ['start_idx','end_idx']\n",
    "    dfz = pd.DataFrame(sl)\n",
    "    dfz.columns = ['slice_obj']\n",
    "    dfy = pd.concat([cbdf, dfx[['start_idx','end_idx']],dfz[['slice_obj']]], axis=1)\n",
    "    dfy.to_pickle(cbkpickle)\n",
    "    \n",
    "def read_codebook(cbkpickle):\n",
    "    cbdf = pd.read_pickle(cbkpickle)\n",
    "    #print('column slice_obj is ',type(a[0]),'\\n')\n",
    "    #print('Saved codebook',batch)\n",
    "    return cbdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebook Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15 Length of data: 79 79 79\n"
     ]
    }
   ],
   "source": [
    "for batch in dctp:\n",
    "    vd = batch\n",
    "    batch = vd['batch']\n",
    "    path = vd['path']+'\\\\'\n",
    "    cbkfile = vd['path']+'\\\\'+vd['cbkfilename']\n",
    "    cbkcols = vd['cbkcol'].split(',')\n",
    "    cendata = vd['path']+'\\\\'+vd['cendata']\n",
    "    pattern = vd['pattern']\n",
    "    cbkpickle = vd['path']+'\\\\'+vd['cbkname']+'.pickle'\n",
    "    cbkdat = read_codebook_text(cbkfile, pattern)\n",
    "    cbdf = codebook_to_df(cbkdat, cbkcols)\n",
    "    c = parse_codebook(cbdf)\n",
    "    sl = slice_codebook(c)\n",
    "    save_codebook(cbdf, c, sl, cbkpickle)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
