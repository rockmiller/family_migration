{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4d13f6",
   "metadata": {},
   "source": [
    "Sort Order Verification (verify_sort.py)<br>\n",
    "<small>Verifies that a gzipped CSV file is sorted by (cenyear, stateicp, countyicp, serial)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import polars as pl\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "# Define base path for input files\n",
    "BASE_PATH = Path(\"D:/source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e306501",
   "metadata": {},
   "source": [
    "Verification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0361d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sort_view(con, csv_path: Path):\n",
    "    query = f\"\"\"\n",
    "        CREATE VIEW src AS\n",
    "        SELECT cenyear, stateicp, countyicp, serial\n",
    "        FROM read_csv_auto('{csv_path}', header=true, compression='gzip');\n",
    "    \"\"\"\n",
    "    con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfe4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inversions(con) -> tuple[int, int]:\n",
    "    query = \"\"\"\n",
    "        SELECT COUNT(*) AS total,\n",
    "               SUM(year_inv + state_inv + county_inv + serial_inv) AS inversions\n",
    "        FROM (\n",
    "            SELECT\n",
    "                cenyear,\n",
    "                stateicp,\n",
    "                countyicp,\n",
    "                serial,\n",
    "                CASE WHEN cenyear   < LAG(cenyear)   OVER () THEN 1 ELSE 0 END AS year_inv,\n",
    "                CASE WHEN stateicp < LAG(stateicp) OVER () THEN 1 ELSE 0 END AS state_inv,\n",
    "                CASE WHEN countyicp< LAG(countyicp)OVER () THEN 1 ELSE 0 END AS county_inv,\n",
    "                CASE WHEN serial   < LAG(serial)   OVER () THEN 1 ELSE 0 END AS serial_inv\n",
    "            FROM src\n",
    "        ) AS lagged\n",
    "    \"\"\"\n",
    "    con.execute(query)\n",
    "    return con.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e7243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sort_verification(filename: str) -> tuple[int, int]:\n",
    "    csv_path = BASE_PATH / filename\n",
    "    con = duckdb.connect()\n",
    "    create_sort_view(con, csv_path)\n",
    "    return compute_inversions(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ec4b6",
   "metadata": {},
   "source": [
    "Tabulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00340346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sort_results(filelist: list[str]) -> pl.DataFrame:\n",
    "    rows = []\n",
    "    for filename in filelist:\n",
    "        print(f\"Verifying: {filename}\")\n",
    "        csv_path = Path(filename)\n",
    "        total, inversions = run_sort_verification(csv_path)\n",
    "        rows.append([filename, total, inversions])\n",
    "    return pl.DataFrame(rows, schema=[\"Filename\", \"Total rows\", \"Sort violations\"], orient='row')\n",
    "\n",
    "def print_table(df: pl.DataFrame):\n",
    "    print(\"\\n\" + tabulate(df.rows(), headers=df.columns, tablefmt=\"github\") + \"\\n\")\n",
    "\n",
    "def save_sort_summary(df: pl.DataFrame):\n",
    "    output_filename = SUMMARY_PATH / \"source_table_sort_verification.csv\"\n",
    "    df.write_csv(str(output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9ca375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying: cs1850.csv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a5511e0c74823b49b49b80e29db12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying: cs1860.csv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a18d15b61e4d2284ecad363840dea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Filename      |   Total rows |   Sort violations |\n",
      "|---------------|--------------|-------------------|\n",
      "| cs1850.csv.gz |     15176114 |                73 |\n",
      "| cs1860.csv.gz |     21050108 |               256 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SUMMARY_PATH = Path(\"D:/source/summaries\")\n",
    "SUMMARY_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filelist = [\"cs1850.csv.gz\",\"cs1860.csv.gz\"]\n",
    "summary_table = collect_sort_results(filelist)\n",
    "print_table(summary_table)\n",
    "save_sort_summary(summary_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
