{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5ca8e0",
   "metadata": {},
   "source": [
    "Census Record Summary (summarize_csv.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c47020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import polars as pl\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "# Define base path for input files\n",
    "BASE_PATH = Path(\"D:/source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38807199",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_census_view(con, filename: str):\n",
    "    csv_path = BASE_PATH / filename\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE VIEW census AS\n",
    "        SELECT\n",
    "            *,\n",
    "            CAST(cenyear AS TEXT) || '-' || CAST(serial AS TEXT) AS hhid,\n",
    "            CAST(stateicp AS TEXT) || '-' || CAST(countyicp AS TEXT) AS locid,\n",
    "            CAST(cenyear AS TEXT) || '-' || CAST(serial AS TEXT) || '-' || CAST(histid AS TEXT) AS pid\n",
    "        FROM read_csv_auto('{csv_path}', header=true, compression='gzip');\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratios(con):\n",
    "    query = \"\"\"\n",
    "        WITH base AS (\n",
    "            SELECT hhid, locid, pid FROM census\n",
    "        ),\n",
    "        counts AS (\n",
    "            SELECT\n",
    "                COUNT(*) AS total_records,\n",
    "                COUNT(DISTINCT hhid) AS total_hhids,\n",
    "                COUNT(DISTINCT locid) AS total_locids,\n",
    "                COUNT(DISTINCT pid) AS total_pids\n",
    "            FROM base\n",
    "        ),\n",
    "        ratios AS (\n",
    "            SELECT\n",
    "                total_records,\n",
    "                total_hhids,\n",
    "                total_locids,\n",
    "                total_pids,\n",
    "                ROUND(CAST(total_pids AS DOUBLE) / total_hhids, 2) AS avg_pids_per_hhid,\n",
    "                ROUND(CAST(total_hhids AS DOUBLE) / total_locids, 2) AS avg_hhids_per_locid\n",
    "            FROM counts\n",
    "        )\n",
    "        SELECT * FROM ratios;\n",
    "    \"\"\"\n",
    "    return con.execute(query).fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6e956",
   "metadata": {},
   "source": [
    "Summarize the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28589d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_csv(filename: str) -> tuple[tuple, float]:\n",
    "    print(f\"Processing: {filename}\")  # ✅ appears before progress bar\n",
    "    con = duckdb.connect(database=':memory:', read_only=False)\n",
    "    create_census_view(con, filename)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    ratios = compute_ratios(con)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    elapsed = round(end - start, 3)  # seconds, rounded for readability\n",
    "    return ratios, elapsed\n",
    "\n",
    "def collect_summaries(filelist: list[str]) -> dict[str, tuple]:\n",
    "    summary_results = {}\n",
    "    for filename in filelist:\n",
    "        ratios, seconds = summarize_csv(filename)\n",
    "        summary_results[filename] = ratios + (seconds,)  # append time to tuple\n",
    "    return summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(summary_results: dict) -> pl.DataFrame:\n",
    "    rows = [[fname] + list(vals) for fname, vals in summary_results.items()]\n",
    "    columns = [\n",
    "        \"filename\",\n",
    "        \"records\",\n",
    "        \"hhids\",\n",
    "        \"locids\",\n",
    "        \"pids\",\n",
    "        \"pids/hhid\",\n",
    "        \"hhids/locid\",\n",
    "        \"seconds\"  # ⏱️ new column\n",
    "    ]\n",
    "    return pl.DataFrame(rows, schema=columns,orient='row')\n",
    "\n",
    "def print_table(df: pl.DataFrame):\n",
    "    print(\"\\n\" + tabulate(df.rows(), headers=df.columns, tablefmt=\"github\") + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e962745",
   "metadata": {},
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\"cs1850.csv.gz\", \"cs1860.csv.gz\",\"cs1870.csv.gz\",\"cs1880.csv.gz\",\"cs1900.csv.gz\",\"cs1910.csv.gz\",\"cs1920.csv.gz\"]\n",
    "\n",
    "# Define output path\n",
    "SUMMARY_PATH = Path(\"D:/source/summaries\")\n",
    "SUMMARY_PATH.mkdir(parents=True, exist_ok=True)  # ensure folder exists\n",
    "\n",
    "summary_results = collect_summaries(filelist)\n",
    "summary_table = create_table(summary_results)\n",
    "summary_table.write_csv(\"summary_table.csv\")\n",
    "print_table(summary_table)\n",
    "\n",
    "# Write to CSV with prefix\n",
    "output_filename = SUMMARY_PATH / f\"source_table_processing_summary.csv\"\n",
    "summary_table.write_csv(str(output_filename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (family_migration)",
   "language": "python",
   "name": "family_migration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
